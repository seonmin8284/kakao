from sentence_transformers import SentenceTransformer, util
from typing import Dict, List, Any, Tuple
import asyncio

# ê¸€ë¡œë²Œ ë³€ìˆ˜ë¡œ ê²°ê³¼ ì €ì¥
ANALYSIS_RESULTS: Dict[str, str] = {}

# ëª¨ë¸ ë¡œë”©
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

SIMILARITY_THRESHOLD = 0.75

# í”„ë¡œì íŠ¸ ë°ì´í„°ëŠ” main.pyì—ì„œ ê°€ì ¸ì˜¬ ì˜ˆì •
PROJECT_TO_OUTPUTS: Dict[str, List[str]] = {}
SERVICE_CATEGORIES: Dict[str, Dict[str, Any]] = {}

async def find_similar_project(query: str) -> Tuple[str, float]:
    query_embedding = model.encode(query)
    max_similarity = 0
    best_match = None
    
    for project, features in PROJECT_TO_OUTPUTS.items():
        text = f"{project} - {', '.join(features)}"
        similarity = util.pytorch_cos_sim(query_embedding, model.encode(text)).item()
        if similarity > max_similarity:
            max_similarity = similarity
            best_match = project
    
    return best_match, max_similarity

def extract_outputs_from_text(text: str) -> List[str]:
    matched = []
    all_outputs = set(sum(PROJECT_TO_OUTPUTS.values(), []))
    for output in all_outputs:
        if output.lower().replace("_", "") in text.lower().replace(" ", ""):
            matched.append(output)
    return matched

async def process_utterance_async(user_id: str, utterance: str):
    """ë¹„ë™ê¸°ë¡œ ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ìš°ì„  ë§¤ì¹­
        for category in SERVICE_CATEGORIES.keys():
            if category.replace("_", " ").lower() in utterance.lower():
                services = SERVICE_CATEGORIES[category]
                total_cost = sum(s["cost"] for s in services.values() if isinstance(s, dict) and "cost" in s)
                response_text = f"[{category.replace('_', ' ')} ì„œë¹„ìŠ¤ ìƒì„¸ ê²¬ì ]\n\n"
                
                # ê° ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
                for name, info in services.items():
                    if isinstance(info, dict) and "features" in info:
                        response_text += f"\nâ–¶ {name.replace('_', ' ')}\n"
                        response_text += f"- ë¹„ìš©: {info['cost']:,}ì›\n"
                        response_text += "- ì£¼ìš” ê¸°ëŠ¥:\n"
                        for f in info["features"]:
                            response_text += f"  Â· {f}\n"
                        if "outputs" in info:
                            response_text += "- ì‚°ì¶œë¬¼:\n"
                            for o in info["outputs"]:
                                response_text += f"  Â· {o}\n"
                
                response_text += f"\nğŸ’° ì´ ê²¬ì : {total_cost:,}ì›"
                ANALYSIS_RESULTS[user_id] = response_text
                return

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
        matched_outputs = extract_outputs_from_text(utterance)
        if matched_outputs:
            matched_projects = [
                proj for proj, outs in PROJECT_TO_OUTPUTS.items()
                if all(output in outs for output in matched_outputs)
            ]
            if matched_projects:
                response_text = "ğŸ¯ ìš”ì²­í•˜ì‹  ê¸°ëŠ¥ì„ í¬í•¨í•˜ëŠ” í”„ë¡œì íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤:\n\n"
                for proj in matched_projects[:3]:
                    response_text += f"ğŸ“Œ {proj}\n"
                    response_text += "ì£¼ìš” ê¸°ëŠ¥:\n"
                    for output in PROJECT_TO_OUTPUTS[proj]:
                        response_text += f"- {output}\n"
                    response_text += "\n"
            else:
                response_text = f"âŒ ìš”ì²­í•˜ì‹  ê¸°ëŠ¥({', '.join(matched_outputs)})ì„ í¬í•¨í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        else:
            # BERT ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
            similar_project, similarity = await find_similar_project(utterance)
            if similarity >= SIMILARITY_THRESHOLD:
                features = PROJECT_TO_OUTPUTS[similar_project]
                response_text = f"ğŸ’¡ ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤ (ìœ ì‚¬ë„: {similarity:.2%}):\n\n"
                response_text += f"í”„ë¡œì íŠ¸: {similar_project}\n\nê¸°ëŠ¥ ëª©ë¡:\n"
                for f in features:
                    response_text += f"âœ“ {f}\n"
            else:
                response_text = "ğŸ” ë‹¤ìŒ ì¤‘ ì–´ë–¤ ì¢…ë¥˜ì˜ ì„œë¹„ìŠ¤ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”?\n\n"
                for cat in SERVICE_CATEGORIES:
                    response_text += f"â€¢ {cat.replace('_', ' ')}\n"

        ANALYSIS_RESULTS[user_id] = response_text

    except Exception as e:
        ANALYSIS_RESULTS[user_id] = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def set_project_data(project_data: Dict[str, List[str]], service_categories: Dict[str, Dict[str, Any]]):
    """í”„ë¡œì íŠ¸ ë°ì´í„° ì„¤ì • í•¨ìˆ˜"""
    global PROJECT_TO_OUTPUTS, SERVICE_CATEGORIES
    PROJECT_TO_OUTPUTS = project_data
    SERVICE_CATEGORIES = service_categories 