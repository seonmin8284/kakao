from fastapi import FastAPI, Request, BackgroundTasks
from fastapi.responses import JSONResponse
import openai
from dotenv import load_dotenv
import os
from typing import Dict, Any
import uuid
from difflib import get_close_matches

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

# ì €ì¥ì†Œ (ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” DBë‚˜ Redis ì‚¬ìš©)
GPT_RESPONSES: Dict[str, str] = {}
USER_INPUTS: Dict[str, str] = {}
USER_SLOT_STATE: Dict[str, Dict[str, str]] = {}

# ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°ì´í„°
SERVICE_CATEGORIES = {
    "ì‹œê°í™”_ëŒ€ì‹œë³´ë“œ": {
        "ê¸°íš_ìš”êµ¬ì‚¬í•­_ì •ì˜": {
            "features": ["ë¶„ì„ ëª©ì  ë° ì£¼ìš” KPI ì •ì˜", "ì‚¬ìš©ì ìš”êµ¬ ì •ë¦¬", "ë°ì´í„° ì‹œê°í™” ë°©í–¥ ìˆ˜ë¦½"],
            "cost": 400000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ì „ì²˜ë¦¬": {
            "features": ["ë‚´ë¶€/ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘", "ë°ì´í„° ì •ì œ ë° ê°€ê³µ", "Power BI/Tableau ì ì¬"],
            "cost": 800000
        },
        "ëŒ€ì‹œë³´ë“œ_í”„ë¡œí† íƒ€ì…_ì œì‘": {
            "features": ["í•µì‹¬ KPI ìœ„ì£¼ì˜ ì‹œê°í™” ëª¨ë“ˆ ê°œë°œ", "í”¼ë“œë°± ë°˜ì˜ êµ¬ì¡° êµ¬ì„±"],
            "cost": 1000000
        },
        "ì‚¬ìš©ì_ë§ì¶¤í˜•_ê¸°ëŠ¥_ì¶”ê°€": {
            "features": ["í•„í„°", "Drill-Down", "ê¶Œí•œë³„ ë·°", "ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ ìë™í™”"],
            "cost": 1000000
        },
        "ìë™í™”_ìš´ì˜_ì—°ë™": {
            "features": ["ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸", "ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§(Airflow)", "ì•Œë¦¼/ë¦¬í¬íŠ¸ ìë™í™”"],
            "cost": 1000000
        }
    },
    "AI_ì±—ë´‡": {
        "ê¸°íš_ì¡°ì‚¬": {
            "features": ["ìš”êµ¬ì‚¬í•­ ë¶„ì„", "ìœ ì¦ˆì¼€ì´ìŠ¤ ì •ì˜", "ê²½ìŸ ë¶„ì„", "AI í™œìš©ë°©ì•ˆ ì„¤ê³„"],
            "cost": 500000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ì „ì²˜ë¦¬": {
            "features": ["í¬ë¡¤ë§", "ì •ì œ", "ë ˆì´ë¸”ë§", "í† í¬ë‚˜ì´ì§•", "ì´ë¯¸ì§€/ìŒì„±/í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì„±"],
            "cost": 500000
        },
        "AI_ëª¨ë¸_ê°œë°œ": {
            "APIê³ ë„í™”": {
                "features": ["ìŒì„±/ì´ë¯¸ì§€/ì–¸ì–´ ìƒì„± ë˜ëŠ” ì¸ì‹ ëª¨ë¸ ê°œë°œ", "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§"],
                "cost": 2000000
            },
            "íŒŒì¸íŠœë‹": {
                "features": ["ì˜¤í”ˆì†ŒìŠ¤ LLM (LLaMA, Mistral ë“±) Fine-tuning", "ë°ì´í„° ê¸°ë°˜ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì„±"],
                "cost": 3000000
            }
        },
        "ëª¨ë¸_í‰ê°€_ê°œì„ ": {
            "features": ["ì •í™•ë„/ì •ë°€ë„/F1 Score", "ì‹¤ì œ QA ì‹œë‚˜ë¦¬ì˜¤ ì„±ëŠ¥ í‰ê°€", "ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„"],
            "cost": 1500000
        },
        "í”Œë«í¼_MVP_êµ¬í˜„": {
            "features": ["ë°±ì—”ë“œ API", "ì±—ë´‡ UI(ì›¹/ì•±)", "ì¸ì¦/ê¶Œí•œ ì‹œìŠ¤í…œ", "ëŒ€í™” íë¦„ êµ¬í˜„"],
            "cost": 3000000
        },
        "ìš´ì˜_ìë™í™”_ëª¨ë‹ˆí„°ë§": {
            "features": ["ëª¨ë¸ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸", "ë¡œê·¸ ìˆ˜ì§‘", "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"],
            "cost": 1000000
        }
    },
    "ë°ì´í„°_ì—”ì§€ë‹ˆì–´ë§": {
        "ìš”êµ¬ì‚¬í•­_ì •ì˜_ì„¤ê³„": {
            "features": ["ìˆ˜ì§‘ ëŒ€ìƒ ì •ì˜", "ìŠ¤í‚¤ë§ˆ ì„¤ê³„", "íŒŒì´í”„ë¼ì¸ êµ¬ì¡° ì„¤ê³„"],
            "cost": 500000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ëª¨ë“ˆ_ê°œë°œ": {
            "features": ["Public API", "ì›¹ í¬ë¡¤ë§", "DB ì¶”ì¶œ ë“± ë°ì´í„° ìˆ˜ì§‘ ìë™í™” êµ¬í˜„"],
            "cost": 500000
        },
        "ë°ì´í„°_ì²˜ë¦¬_ì •ì œ": {
            "features": ["ê²°ì¸¡ì¹˜ ì²˜ë¦¬", "ì¤‘ë³µ ì œê±°", "í¬ë§· ë³€í™˜", "ì»¬ëŸ¼ ì •ë¦¬ ë“± ì „ì²˜ë¦¬ ë¡œì§ ê°œë°œ"],
            "cost": 500000
        },
        "ì €ì¥_ì ì¬_ìë™í™”": {
            "features": ["ì •ì œ ë°ì´í„°ì˜ ì €ì¥ (SQL, Data Lake, Warehouse ë“±) ë° ë²„ì „ ê´€ë¦¬"],
            "cost": 500000
        },
        "íŒŒì´í”„ë¼ì¸_ìë™í™”": {
            "features": ["Apache Airflow", "Python ìŠ¤ì¼€ì¤„ëŸ¬", "CI/CD ë“± í™œìš©í•œ ìë™í™” êµ¬ì„±"],
            "cost": 700000
        },
        "ëª¨ë‹ˆí„°ë§_ì˜¤ë¥˜_ì•Œë¦¼": {
            "features": ["ì‹¤íŒ¨ ë¡œê·¸ ìˆ˜ì§‘", "ì‘ì—… ì„±ê³µ ì—¬ë¶€ ì‹œê°í™”", "ìŠ¬ë™/ë©”ì¼ ì•Œë¦¼ ì—°ë™"],
            "cost": 500000
        }
    },
    "ì›¹_í”Œë«í¼": {
        "ê¸°íš_ìš”êµ¬ì‚¬í•­_ì •ì˜": {
            "features": ["ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„", "í•µì‹¬ ê¸°ëŠ¥ ë„ì¶œ", "ê²½ìŸ ë²¤ì¹˜ë§ˆí‚¹", "í”Œë«í¼ êµ¬ì¡° ì„¤ê³„", "ê¸°ìˆ  ìŠ¤íƒ ì„ ì •"],
            "cost": 1000000
        },
        "í”„ë¡ íŠ¸ì—”ë“œ_ê°œë°œ": {
            "features": ["ì‚¬ìš©ì UI/UX êµ¬í˜„ (React/Vue ê¸°ë°˜)", "ë°˜ì‘í˜• ë””ìì¸ ì ìš©"],
            "cost": 2000000
        },
        "ë°±ì—”ë“œ_ê°œë°œ": {
            "features": ["API ì„œë²„", "ì¸ì¦ ì‹œìŠ¤í…œ", "DB ì—°ë™", "ì•Œë¦¼ ì‹œìŠ¤í…œ ë“± êµ¬í˜„"],
            "cost": 3000000
        },
        "ìš´ì˜ì_ê´€ë¦¬_ì‹œìŠ¤í…œ": {
            "features": ["ê´€ë¦¬ì í˜ì´ì§€", "ê¶Œí•œ ê´€ë¦¬", "ì‚¬ìš©ì/ë°ì´í„° ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥"],
            "cost": 2000000
        },
        "ë°°í¬_í†µí•©_ìœ ì§€ë³´ìˆ˜": {
            "features": ["ë„ë©”ì¸ ì—°ë™", "ì„œë²„ ë°°í¬", "ì´ˆê¸° ì˜¤ë¥˜ ëŒ€ì‘ ë° ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ ì œê³µ"],
            "cost": 1000000
        }
    }
}

# ì‚°ì¶œë¬¼ ê´€ë ¨ í‚¤ì›Œë“œ
SANCHUL_ENTRIES = [
    "ì›¹", "ì›¹ì‚¬ì´íŠ¸", "ì±—ë´‡", "í”Œë«í¼", "ETL", "ì‹œìŠ¤í…œ", "ì•±", "ì‚¬ì´íŠ¸", "MVP", "UI", "ëŒ€ì‹œë³´ë“œ",
    "API", "ê´€ë¦¬ì í˜ì´ì§€", "ë¦¬í¬íŠ¸", "ë³´ê³ ì„œ", "ìë™í™”", "ì•ˆë“œë¡œì´ë“œ", "IOS", "ì›¹ì•±"
]

SANCHUL_SYNONYMS = [kw.lower() for kw in SANCHUL_ENTRIES]  # ì†Œë¬¸ì ë¹„êµìš© ë¦¬ìŠ¤íŠ¸

# ì£¼ì œ ê´€ë ¨ í‚¤ì›Œë“œ
JUJAE_ENTRIES = [
    "ì—ë„ˆì§€", "ì „ê¸°", "êµìœ¡", "ì‹¬ë¦¬", "ì‚¬ì£¼", "ê±´ê°•", "ë³‘ì›", "ì§„ë£Œ", "ì˜ë£Œ", "ì •ì‹ ê±´ê°•",
    "ê°•ì˜", "í•™ìŠµ", "ìˆ˜ê°•", "íŠœí„°ë§", "ê¸ˆìœµ", "ì†¡ê¸ˆ", "ìì‚°", "íˆ¬ì", "ë³´í—˜", "ì‡¼í•‘ëª°",
    "ë§ˆì¼“", "ê²°ì œ", "ë¦¬ë·°", "ì¶”ì²œ", "ìŒì„±ì¸ì‹", "ì´ë¯¸ì§€ ìƒì„±", "ì±—GPT", "ë©”ì‹ ì €",
    "ì±„íŒ…", "í˜‘ì—…", "ì¼ì •", "CRM", "ERP", "ì›Œí¬í”Œë¡œìš°", "í”„ë¡œì íŠ¸ ê´€ë¦¬", "ê³„ì•½ì„œ",
    "ë³´ê³ ì„œ", "PDF ìš”ì•½", "ì˜ˆì•½", "ë§¤ì¹­", "ë¯¸ìš©ì‹¤", "ìƒë‹´", "ìê°€ ì§„ë‹¨", "ìŠµê´€ ê´€ë¦¬",
    "í–‰ì •", "ë¯¼ì›", "ì •ì±…", "ë°°ì†¡", "íƒì‹œ", "ë¬¼ë¥˜", "íƒ„ì†Œë°°ì¶œ",
    # êµìœ¡/ë°œë‹¬ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
    "ì§€ëŠ¥", "ê²½ê³„ì„  ì§€ëŠ¥", "íŠ¹ìˆ˜êµìœ¡", "ë°œë‹¬", "ì¸ì§€", "ì½ê¸°", "í•™ìŠµì¥ì• ", "ì–¸ì–´", "ì•„ë™", "í”„ë¡œê·¸ë¨"
]

JUJAE_SYNONYMS = [kw.lower() for kw in JUJAE_ENTRIES]  # ì†Œë¬¸ì ë¹„êµìš© ë¦¬ìŠ¤íŠ¸

def match_similar_slot_lightweight(text: str, slot_type: str) -> str:
    """ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ì£¼ì œ ë˜ëŠ” ì‚°ì¶œë¬¼ì„ ë°˜í™˜"""
    candidates = SANCHUL_ENTRIES if slot_type == "ì‚°ì¶œë¬¼" else JUJAE_ENTRIES
    matches = get_close_matches(text, candidates, n=1, cutoff=0.5)  # cutoff ê°’ì„ 0.5ë¡œ ë‚®ì¶¤
    return matches[0] if matches else ""

def is_likely_output(text: str) -> bool:
    """ì‚°ì¶œë¬¼ ìŠ¬ë¡¯ì— ë“¤ì–´ê°ˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ì§€ íŒë‹¨"""
    lower_text = text.lower().strip()
    return any(entry in lower_text for entry in SANCHUL_SYNONYMS)

def is_likely_topic(text: str) -> bool:
    """ì£¼ì œ ìŠ¬ë¡¯ì— ë“¤ì–´ê°ˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ì§€ íŒë‹¨"""
    lower_text = text.lower().strip()
    return any(entry in lower_text for entry in JUJAE_SYNONYMS)

def is_valid_slot_answer(text: str) -> bool:
    """ì‚¬ìš©ì ì…ë ¥ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    text = text.strip()
    if len(text) < 3:
        return False
    lower = text.lower()
    invalid_keywords = ["ì—†", "ëª¨ë¥´", "ëª¨ë¦„", "ëª°ë¼", "ê¸€ì„", "ë¬´", "ì˜ ëª°ë¼", "ê¸°ì–µ ì•ˆ", "ìƒê° ì•ˆ"]
    return not any(kw in lower for kw in invalid_keywords)

def is_valid_period(text: str) -> bool:
    """ê¸°ê°„ ì…ë ¥ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    text = text.strip()
    if not is_valid_slot_answer(text):  # ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬
        return False
    # ìˆ«ìê°€ í¬í•¨ë˜ì–´ ìˆê³ , ë‹¨ìœ„ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    has_number = any(char.isdigit() for char in text)
    has_unit = any(unit in text for unit in ["ì¼", "ê°œì›”", "ë‹¬", "ì£¼", "ë…„"])
    return has_number and has_unit

def infer_primary_category(topic: str, output: str) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤."""
    output = output.lower()
    topic = topic.lower()
    
    # ì›¹ í”Œë«í¼ ê´€ë ¨ í‚¤ì›Œë“œ
    if any(kw in output for kw in ["ì•±", "ì›¹", "ì‚¬ì´íŠ¸", "í”Œë«í¼", "ê´€ë¦¬ì", "ui", "í˜ì´ì§€"]):
        return "ì›¹_í”Œë«í¼"
    
    # AI ì±—ë´‡ ê´€ë ¨ í‚¤ì›Œë“œ
    elif any(kw in output for kw in ["ì±—ë´‡", "ai", "ëŒ€í™”", "ì§ˆì˜ì‘ë‹µ"]) or \
         any(kw in topic for kw in ["ëŒ€í™”", "ìƒë‹´", "ì‘ë‹µ", "ì§ˆë¬¸"]):
        return "AI_ì±—ë´‡"
    
    # ë°ì´í„°/ì‹œê°í™” ê´€ë ¨ í‚¤ì›Œë“œ
    elif any(kw in output for kw in ["ëŒ€ì‹œë³´ë“œ", "ì‹œê°í™”", "ë¶„ì„", "ë¦¬í¬íŠ¸"]) or \
         any(kw in topic for kw in ["ë°ì´í„°", "ë¶„ì„", "í†µê³„", "í˜„í™©"]):
        return "ì‹œê°í™”_ëŒ€ì‹œë³´ë“œ"
    
    # ê¸°ë³¸ê°’ì€ ì›¹ í”Œë«í¼
    return "ì›¹_í”Œë«í¼"

def build_prompt(user_input: str, service_categories: Dict[str, Any], topic: str = "", output: str = "") -> str:
    """ì‚¬ìš©ì ì…ë ¥ê³¼ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPT í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ì£¼ìš” ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
    primary_hint = infer_primary_category(topic, output)
    
    prompt = f"ì‚¬ìš©ìì˜ ìš”ì²­:\n\"{user_input}\"\n\n"
    prompt += f"ğŸ’¡ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ìš” ì„œë¹„ìŠ¤ëŠ” `{primary_hint}`ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n\n"
    prompt += "ìš°ë¦¬ íšŒì‚¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n"

    for category, steps in service_categories.items():
        prompt += f"\nğŸ“‚ {category.replace('_', ' ')}\n"
        for step, content in steps.items():
            if isinstance(content, dict) and "features" in content:
                cost = content.get("cost", 0)
                features = " / ".join(content["features"])
                prompt += f"  - {step.replace('_', ' ')}: {features} (ë¹„ìš©: {cost:,}ì›)\n"
            elif isinstance(content, dict):
                for substep, subcontent in content.items():
                    if "features" in subcontent:
                        cost = subcontent.get("cost", 0)
                        features = " / ".join(subcontent["features"])
                        prompt += f"  - {step.replace('_', ' ')} > {substep}: {features} (ë¹„ìš©: {cost:,}ì›)\n"

    prompt += "\në‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”:\n"
    prompt += "1. ì¶”ì²œ ì„œë¹„ìŠ¤: ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬\n"
    prompt += "2. í•„ìš”í•œ ë‹¨ê³„: ê° ë‹¨ê³„ë³„ ì£¼ìš” ê¸°ëŠ¥ê³¼ ë¹„ìš©\n"
    prompt += "3. ì˜ˆìƒ ê¸°ê°„: ì „ì²´ í”„ë¡œì íŠ¸ ì†Œìš” ê¸°ê°„\n"
    prompt += "4. ì´ ê²¬ì : ëª¨ë“  ë‹¨ê³„ì˜ ë¹„ìš© í•©ê³„\n"
    prompt += "5. ì¶”ê°€ ê³ ë ¤ì‚¬í•­: ì„ íƒì ìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ë‚˜ ëŒ€ì•ˆ\n"
    
    return prompt

def call_gpt_for_estimate(user_input: str, topic: str = "", output: str = "") -> str:
    """GPT APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê²¬ì  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        prompt = build_prompt(user_input, SERVICE_CATEGORIES, topic, output)
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ê²¬ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ìƒë‹´í•´ì£¼ì„¸ìš”. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ë˜, í˜•ì‹ì€ ë°˜ë“œì‹œ ì§€ì •ëœ ëŒ€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=700
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ ì£„ì†¡í•©ë‹ˆë‹¤. ê²¬ì  ì‚°ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\nì˜¤ë¥˜ ë‚´ìš©: {str(e)}"

# ë¹„ë™ê¸° GPT ìš”ì²­ ì²˜ë¦¬
async def process_gpt(user_id: str, user_input: str, topic: str = "", output: str = ""):
    USER_INPUTS[user_id] = user_input
    GPT_RESPONSES[user_id] = "â³ ìš”ì²­ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
    GPT_RESPONSES[user_id] = call_gpt_for_estimate(user_input, topic, output)

@app.post("/kakao/webhook")
async def kakao_webhook(request: Request, background_tasks: BackgroundTasks):
    """ì¹´ì¹´ì˜¤í†¡ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸"""
    # ë³€ìˆ˜ ì´ˆê¸°í™”
    user_id = ""
    utterance = ""
    params = {}
    detail_params = {}



    try:
        body = await request.json()
        user_id = body.get("userRequest", {}).get("user", {}).get("id", str(uuid.uuid4()))
        utterance = body.get("userRequest", {}).get("utterance", "")
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ìƒì„¸ íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        params = body.get("action", {}).get("params", {})
        detail_params = body.get("action", {}).get("detailParams", {})
        
        # ê²¬ì  ê²°ê³¼ í™•ì¸ ìš”ì²­ ì²˜ë¦¬
        if utterance.startswith("ê²¬ì  ê²°ê³¼ í™•ì¸:"):
            result_user_id = utterance.split("ê²¬ì  ê²°ê³¼ í™•ì¸:")[-1].strip()
            return await get_result(result_user_id)
            
        # ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜ ì‹œ ìƒíƒœ ì´ˆê¸°í™”
        if utterance == "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜":
            USER_SLOT_STATE.pop(user_id, None)
            USER_INPUTS.pop(user_id, None)
            GPT_RESPONSES.pop(user_id, None)
        
        # ìŠ¬ë¡¯ í•„ë§ ì¤‘ì¸ì§€ ì—¬ë¶€ í™•ì¸
        in_slot_filling = user_id in USER_SLOT_STATE and any(
            USER_SLOT_STATE[user_id].get(slot, "") == "" for slot in ["ì£¼ì œ", "ì‚°ì¶œë¬¼", "ê¸°ê°„"]
        )
        
        # ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ â†’ ìŠ¬ë¡¯ í•„ë§ ì¤‘ì´ë©´ ê²€ì‚¬ ê±´ë„ˆëœ€
        if not in_slot_filling and not any(keyword in utterance for keyword in ["í¬íŠ¸í´ë¦¬ì˜¤", "ê°€ê²©", "ê²¬ì ", "ë¹„ìš©", "í”„ë¡œì íŠ¸", "ê°œë°œ", "ì œì‘"]):
            return JSONResponse(content={
                "version": "2.0",
                "template": {
                    "outputs": [{
                        "simpleText": {
                            "text": "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸ê³¼ ê²¬ì  ìƒë‹´ë§Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ğŸ˜…\n\në‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë¬¸ì˜í•´ì£¼ì„¸ìš”:\n- í”„ë¡œì íŠ¸ ê²¬ì  ë¬¸ì˜\n- í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸\n- ê°œë°œ ë¹„ìš© ìƒë‹´"
                        }
                    }],
                    "quickReplies": [{
                        "messageText": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜",
                        "action": "message",
                        "label": "ê²¬ì  ë¬¸ì˜í•˜ê¸°"
                    }]
                }
            })
    
        # ê¸°ì¡´ ìƒíƒœ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if user_id not in USER_SLOT_STATE:
            USER_SLOT_STATE[user_id] = {"ì£¼ì œ": "", "ì‚°ì¶œë¬¼": "", "ê¸°ê°„": "", "retry_count": 0}
            
        user_state = USER_SLOT_STATE[user_id]
        
        # í† í°í™” ë° ì „ì²˜ë¦¬
        tokens = utterance.replace(",", " ").replace("ì„", "").replace("ë¥¼", "").split()
        tokens = [t.strip().lower() for t in tokens]
        
        # ì£¼ì œê°€ ë¹„ì–´ ìˆìœ¼ë©´ í† í°ì—ì„œ ë§¤ì¹­ ì‹œë„
        if user_state["ì£¼ì œ"] == "":
            for token in tokens:
                if is_likely_topic(token):
                    user_state["ì£¼ì œ"] = token
                    break
            if user_state["ì£¼ì œ"] == "":
                topic_match = match_similar_slot_lightweight(utterance, "ì£¼ì œ")
                if topic_match:
                    user_state["ì£¼ì œ"] = topic_match
                else:
                    return JSONResponse(content={
                        "version": "2.0",
                        "template": {
                            "outputs": [{
                                "simpleText": {
                                    "text": "ğŸ“ í”„ë¡œì íŠ¸ ì£¼ì œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”! (ì˜ˆ: ì‡¼í•‘ëª°, êµìœ¡ í”Œë«í¼ ë“±)"
                                }
                            }]
                        }
                    })
        
        # ì‚°ì¶œë¬¼ì´ ë¹„ì–´ ìˆìœ¼ë©´ ì—¬ëŸ¬ í† í°ì—ì„œ ì¶”ì¶œ
        if user_state["ì‚°ì¶œë¬¼"] == "":
            matched_outputs = [entry for entry in SANCHUL_SYNONYMS if entry in utterance.lower()]
            if matched_outputs:
                user_state["ì‚°ì¶œë¬¼"] = ", ".join(sorted(set(matched_outputs)))
            else:
                output_match = match_similar_slot_lightweight(utterance, "ì‚°ì¶œë¬¼")
                if output_match:
                    user_state["ì‚°ì¶œë¬¼"] = output_match
                else:
                    return JSONResponse(content={
                        "version": "2.0",
                        "template": {
                            "outputs": [{
                                "simpleText": {
                                    "text": "ğŸ“¦ ì–´ë–¤ ì‚°ì¶œë¬¼ì„ ì›í•˜ì‹œë‚˜ìš”? (ì˜ˆ: ì›¹ì‚¬ì´íŠ¸, ì•±, ê´€ë¦¬ì í˜ì´ì§€ ë“±)"
                                }
                            }]
                        }
                    })
        
        # 4. ê¸°ê°„ ì…ë ¥ì´ ì—†ìœ¼ë©´ ìš”ì²­
        if user_state["ê¸°ê°„"] == "":
            if is_valid_period(utterance):
                user_state["ê¸°ê°„"] = utterance
            else:
                return JSONResponse(content={
                    "version": "2.0",
                    "template": {
                        "outputs": [{
                            "simpleText": {
                                "text": "âŒ› ì˜ˆìƒ ê°œë°œ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì„¸ìš”! (ì˜ˆ: 2ê°œì›”, 3ì£¼ ë“±)"
                            }
                        }]
                    }
                })
        
        # ìƒì„¸ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ê²½ìš° ìš°ì„  ì ìš©
        for slot in ["ì£¼ì œ", "ì‚°ì¶œë¬¼", "ê¸°ê°„"]:
            if slot in detail_params and detail_params[slot].get("origin"):
                user_state[slot] = detail_params[slot]["origin"]
            elif slot in params:
                user_state[slot] = params.get(slot) or params.get(f"${slot}", "")
        
        # ëª¨ë“  ìŠ¬ë¡¯ì´ ì±„ì›Œì§„ ê²½ìš°ì—ë§Œ GPT ìš”ì²­ ì²˜ë¦¬
        if user_state["ì£¼ì œ"] != "" and user_state["ì‚°ì¶œë¬¼"] != "" and user_state["ê¸°ê°„"] != "":
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ
            user_input_parts = [user_state['ì£¼ì œ'], user_state['ì‚°ì¶œë¬¼'], user_state['ê¸°ê°„']]
            user_input_parts = list(dict.fromkeys(user_input_parts))  # ì¤‘ë³µ ì œê±°
            user_input = ", ".join(user_input_parts)
            
            USER_INPUTS[user_id] = user_input
            background_tasks.add_task(process_gpt, user_id, user_input, user_state["ì£¼ì œ"], user_state["ì‚°ì¶œë¬¼"])
            
            return JSONResponse(content={
                "version": "2.0",
                "template": {
                    "outputs": [{
                        "simpleText": {
                            "text": f"ğŸ“ ëª¨ë“  ì •ë³´ë¥¼ ë°›ì•˜ì–´ìš”! ëª‡ ì´ˆ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n\nğŸ‘‰ í™•ì¸: /result/{user_id}"
                        }
                    }],
                    "quickReplies": [{
                        "messageText": f"ê²¬ì  ê²°ê³¼ í™•ì¸:{user_id}",
                        "action": "message",
                        "label": "ê²¬ì  ê²°ê³¼ í™•ì¸"
                    }]
                }
            })
        
    except Exception as e:
        return JSONResponse(content={
            "version": "2.0",
            "template": {
                "outputs": [{
                    "simpleText": {
                        "text": f"âš ï¸ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\nì˜¤ë¥˜ ë‚´ìš©: {str(e)}"
                    }
                }]
            }
        })

@app.get("/result/{user_id}")
async def get_result(user_id: str):
    """ê²°ê³¼ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    response_text = GPT_RESPONSES.get(user_id, "âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìš”ì²­ IDì´ê±°ë‚˜ ì•„ì§ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.")
    user_input = USER_INPUTS.get(user_id, "ì…ë ¥ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì¡°íšŒ í›„ ìƒíƒœ ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
    USER_SLOT_STATE.pop(user_id, None)
    
    return {
        "version": "2.0",
        "template": {
            "outputs": [{
                "simpleText": {
                    "text": f"{response_text}\n\nğŸ—‚ï¸ ì…ë ¥ ì •ë³´:\n{user_input}"
                }
            }],
            "quickReplies": [{
                "messageText": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜",
                "action": "message",
                "label": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜"
            }]
        }
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy"}
