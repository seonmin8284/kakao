from fastapi import FastAPI, Request, BackgroundTasks
from fastapi.responses import JSONResponse
import openai
from dotenv import load_dotenv
import os
from typing import Dict, Any, List
import uuid
from difflib import get_close_matches
import uvicorn
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

# ì €ì¥ì†Œ (ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” DBë‚˜ Redis ì‚¬ìš©)
GPT_RESPONSES: Dict[str, str] = {}
USER_INPUTS: Dict[str, str] = {}
USER_SLOT_STATE: Dict[str, Dict[str, str]] = {}
SHRUNK_RESPONSES: Dict[str, str] = {}

# ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°ì´í„°
SERVICE_CATEGORIES = {
    "ì‹œê°í™”_ëŒ€ì‹œë³´ë“œ": {
        "ê¸°íš_ìš”êµ¬ì‚¬í•­_ì •ì˜": {
            "features": ["ë¶„ì„ ëª©ì  ë° ì£¼ìš” KPI ì •ì˜", "ì‚¬ìš©ì ìš”êµ¬ ì •ë¦¬", "ë°ì´í„° ì‹œê°í™” ë°©í–¥ ìˆ˜ë¦½"],
            "cost": 400000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ì „ì²˜ë¦¬": {
            "features": ["ë‚´ë¶€/ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘", "ë°ì´í„° ì •ì œ ë° ê°€ê³µ", "Power BI/Tableau ì ì¬"],
            "cost": 800000
        },
        "ëŒ€ì‹œë³´ë“œ_í”„ë¡œí† íƒ€ì…_ì œì‘": {
            "features": ["í•µì‹¬ KPI ìœ„ì£¼ì˜ ì‹œê°í™” ëª¨ë“ˆ ê°œë°œ", "í”¼ë“œë°± ë°˜ì˜ êµ¬ì¡° êµ¬ì„±"],
            "cost": 1000000
        },
        "ì‚¬ìš©ì_ë§ì¶¤í˜•_ê¸°ëŠ¥_ì¶”ê°€": {
            "features": ["í•„í„°", "Drill-Down", "ê¶Œí•œë³„ ë·°", "ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ ìë™í™”"],
            "cost": 1000000
        },
        "ìë™í™”_ìš´ì˜_ì—°ë™": {
            "features": ["ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸", "ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§(Airflow)", "ì•Œë¦¼/ë¦¬í¬íŠ¸ ìë™í™”"],
            "cost": 1000000
        }
    },
    "AI_ì±—ë´‡": {
        "ê¸°íš_ì¡°ì‚¬": {
            "features": ["ìš”êµ¬ì‚¬í•­ ë¶„ì„", "ìœ ì¦ˆì¼€ì´ìŠ¤ ì •ì˜", "ê²½ìŸ ë¶„ì„", "AI í™œìš©ë°©ì•ˆ ì„¤ê³„"],
            "cost": 500000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ì „ì²˜ë¦¬": {
            "features": ["í¬ë¡¤ë§", "ì •ì œ", "ë ˆì´ë¸”ë§", "í† í¬ë‚˜ì´ì§•", "ì´ë¯¸ì§€/ìŒì„±/í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì„±"],
            "cost": 500000
        },
        "AI_ëª¨ë¸_ê°œë°œ": {
            "APIê³ ë„í™”": {
                "features": ["ìŒì„±/ì´ë¯¸ì§€/ì–¸ì–´ ìƒì„± ë˜ëŠ” ì¸ì‹ ëª¨ë¸ ê°œë°œ", "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§"],
                "cost": 2000000
            },
            "íŒŒì¸íŠœë‹": {
                "features": ["ì˜¤í”ˆì†ŒìŠ¤ LLM (LLaMA, Mistral ë“±) Fine-tuning", "ë°ì´í„° ê¸°ë°˜ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì„±"],
                "cost": 3000000
            }
        },
        "ëª¨ë¸_í‰ê°€_ê°œì„ ": {
            "features": ["ì •í™•ë„/ì •ë°€ë„/F1 Score", "ì‹¤ì œ QA ì‹œë‚˜ë¦¬ì˜¤ ì„±ëŠ¥ í‰ê°€", "ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„"],
            "cost": 1500000
        },
        "í”Œë«í¼_MVP_êµ¬í˜„": {
            "features": ["ë°±ì—”ë“œ API", "ì±—ë´‡ UI(ì›¹/ì•±)", "ì¸ì¦/ê¶Œí•œ ì‹œìŠ¤í…œ", "ëŒ€í™” íë¦„ êµ¬í˜„"],
            "cost": 3000000
        },
        "ìš´ì˜_ìë™í™”_ëª¨ë‹ˆí„°ë§": {
            "features": ["ëª¨ë¸ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸", "ë¡œê·¸ ìˆ˜ì§‘", "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"],
            "cost": 1000000
        }
    },
    "ë°ì´í„°_ì—”ì§€ë‹ˆì–´ë§": {
        "ìš”êµ¬ì‚¬í•­_ì •ì˜_ì„¤ê³„": {
            "features": ["ìˆ˜ì§‘ ëŒ€ìƒ ì •ì˜", "ìŠ¤í‚¤ë§ˆ ì„¤ê³„", "íŒŒì´í”„ë¼ì¸ êµ¬ì¡° ì„¤ê³„"],
            "cost": 500000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ëª¨ë“ˆ_ê°œë°œ": {
            "features": ["Public API", "ì›¹ í¬ë¡¤ë§", "DB ì¶”ì¶œ ë“± ë°ì´í„° ìˆ˜ì§‘ ìë™í™” êµ¬í˜„"],
            "cost": 500000
        },
        "ë°ì´í„°_ì²˜ë¦¬_ì •ì œ": {
            "features": ["ê²°ì¸¡ì¹˜ ì²˜ë¦¬", "ì¤‘ë³µ ì œê±°", "í¬ë§· ë³€í™˜", "ì»¬ëŸ¼ ì •ë¦¬ ë“± ì „ì²˜ë¦¬ ë¡œì§ ê°œë°œ"],
            "cost": 500000
        },
        "ì €ì¥_ì ì¬_ìë™í™”": {
            "features": ["ì •ì œ ë°ì´í„°ì˜ ì €ì¥ (SQL, Data Lake, Warehouse ë“±) ë° ë²„ì „ ê´€ë¦¬"],
            "cost": 500000
        },
        "íŒŒì´í”„ë¼ì¸_ìë™í™”": {
            "features": ["Apache Airflow", "Python ìŠ¤ì¼€ì¤„ëŸ¬", "CI/CD ë“± í™œìš©í•œ ìë™í™” êµ¬ì„±"],
            "cost": 700000
        },
        "ëª¨ë‹ˆí„°ë§_ì˜¤ë¥˜_ì•Œë¦¼": {
            "features": ["ì‹¤íŒ¨ ë¡œê·¸ ìˆ˜ì§‘", "ì‘ì—… ì„±ê³µ ì—¬ë¶€ ì‹œê°í™”", "ìŠ¬ë™/ë©”ì¼ ì•Œë¦¼ ì—°ë™"],
            "cost": 500000
        }
    },
    "ì›¹_í”Œë«í¼": {
        "ê¸°íš_ìš”êµ¬ì‚¬í•­_ì •ì˜": {
            "features": ["ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„", "í•µì‹¬ ê¸°ëŠ¥ ë„ì¶œ", "ê²½ìŸ ë²¤ì¹˜ë§ˆí‚¹", "í”Œë«í¼ êµ¬ì¡° ì„¤ê³„", "ê¸°ìˆ  ìŠ¤íƒ ì„ ì •"],
            "cost": 1000000
        },
        "í”„ë¡ íŠ¸ì—”ë“œ_ê°œë°œ": {
            "features": ["ì‚¬ìš©ì UI/UX êµ¬í˜„ (React/Vue ê¸°ë°˜)", "ë°˜ì‘í˜• ë””ìì¸ ì ìš©"],
            "cost": 2000000
        },
        "ë°±ì—”ë“œ_ê°œë°œ": {
            "features": ["API ì„œë²„", "ì¸ì¦ ì‹œìŠ¤í…œ", "DB ì—°ë™", "ì•Œë¦¼ ì‹œìŠ¤í…œ ë“± êµ¬í˜„"],
            "cost": 3000000
        },
        "ìš´ì˜ì_ê´€ë¦¬_ì‹œìŠ¤í…œ": {
            "features": ["ê´€ë¦¬ì í˜ì´ì§€", "ê¶Œí•œ ê´€ë¦¬", "ì‚¬ìš©ì/ë°ì´í„° ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥"],
            "cost": 2000000
        },
        "ë°°í¬_í†µí•©_ìœ ì§€ë³´ìˆ˜": {
            "features": ["ë„ë©”ì¸ ì—°ë™", "ì„œë²„ ë°°í¬", "ì´ˆê¸° ì˜¤ë¥˜ ëŒ€ì‘ ë° ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ ì œê³µ"],
            "cost": 1000000
        }
    },
    "ë””ì§€í„¸_ì´ë¯¸ì§€_íˆ´": {
        "ê¸°íš": {
            "features": ["ì‚¬ìš©ì ê¸°ëŠ¥ ì •ì˜", "íˆ´ ì•„í‚¤í…ì²˜ ì„¤ê³„"],
            "cost": 800000
        },
        "íˆ´_ê°œë°œ": {
            "features": ["ì´ë¯¸ì§€ ì—…ë¡œë“œ/í¸ì§‘/ì €ì¥", "í•„í„° ì ìš© ê¸°ëŠ¥", "ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥"],
            "cost": 2000000
        }
    }
}

# ì‚°ì¶œë¬¼ ê´€ë ¨ í‚¤ì›Œë“œ
SANCHUL_ENTRIES = [
    "ì›¹", "ì›¹ì‚¬ì´íŠ¸", "ì±—ë´‡", "ETL", "ì‹œìŠ¤í…œ", "ì•±", "ì‚¬ì´íŠ¸", "MVP", "UI", "ëŒ€ì‹œë³´ë“œ",
    "API", "ê´€ë¦¬ì í˜ì´ì§€", "ë¦¬í¬íŠ¸", "ë³´ê³ ì„œ", "ìë™í™”", "ì•ˆë“œë¡œì´ë“œ", "IOS", "ì›¹ì•±", "í”„ë¡œê·¸ë¨","ìœˆë„ìš°", "ë§¥"
]

SANCHUL_SYNONYMS = [kw.lower() for kw in SANCHUL_ENTRIES]  # ì†Œë¬¸ì ë¹„êµìš© ë¦¬ìŠ¤íŠ¸

# ì£¼ì œ ê´€ë ¨ í‚¤ì›Œë“œ
JUJAE_ENTRIES = [
    "ì—ë„ˆì§€", "ì „ê¸°", "êµìœ¡", "ì‹¬ë¦¬", "ì‚¬ì£¼", "ê±´ê°•", "ë³‘ì›", "ì§„ë£Œ", "ì˜ë£Œ", "ì •ì‹ ê±´ê°•",
    "ê°•ì˜", "í•™ìŠµ", "ìˆ˜ê°•", "íŠœí„°ë§", "ê¸ˆìœµ", "ì†¡ê¸ˆ", "ìì‚°", "íˆ¬ì", "ë³´í—˜", "ì‡¼í•‘ëª°",
    "ë§ˆì¼“", "ê²°ì œ", "ë¦¬ë·°", "ì¶”ì²œ", "ìŒì„±ì¸ì‹", "ì´ë¯¸ì§€ ìƒì„±", "ì±—GPT", "ë©”ì‹ ì €",
    "ì±„íŒ…", "í˜‘ì—…", "ì¼ì •", "CRM", "ERP", "ì›Œí¬í”Œë¡œìš°", "í”„ë¡œì íŠ¸ ê´€ë¦¬", "ê³„ì•½ì„œ",
    "ë³´ê³ ì„œ", "PDF ìš”ì•½", "ì˜ˆì•½", "ë§¤ì¹­", "ë¯¸ìš©ì‹¤", "ìƒë‹´", "ìê°€ ì§„ë‹¨", "ìŠµê´€ ê´€ë¦¬",
    "í–‰ì •", "ë¯¼ì›", "ì •ì±…", "ë°°ì†¡", "íƒì‹œ", "ë¬¼ë¥˜", "íƒ„ì†Œë°°ì¶œ",
    # êµìœ¡/ë°œë‹¬ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
    "ì§€ëŠ¥", "ê²½ê³„ì„  ì§€ëŠ¥", "íŠ¹ìˆ˜êµìœ¡", "ë°œë‹¬", "ì¸ì§€", "ì½ê¸°", "í•™ìŠµì¥ì• ", "ì–¸ì–´", "ì•„ë™", "í”„ë¡œê·¸ë¨"
]

JUJAE_SYNONYMS = [kw.lower() for kw in JUJAE_ENTRIES]  # ì†Œë¬¸ì ë¹„êµìš© ë¦¬ìŠ¤íŠ¸

def match_similar_slot_lightweight(text: str, slot_type: str) -> str:
    """ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ì£¼ì œ ë˜ëŠ” ì‚°ì¶œë¬¼ì„ ë°˜í™˜"""
    candidates = SANCHUL_ENTRIES if slot_type == "ì‚°ì¶œë¬¼" else JUJAE_ENTRIES
    matches = get_close_matches(text, candidates, n=1, cutoff=0.5)  # cutoff ê°’ì„ 0.5ë¡œ ë‚®ì¶¤
    return matches[0] if matches else ""

def is_likely_output(text: str) -> bool:
    """ì‚°ì¶œë¬¼ ìŠ¬ë¡¯ì— ë“¤ì–´ê°ˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ì§€ íŒë‹¨"""
    lower_text = text.lower().strip()
    return any(entry in lower_text for entry in SANCHUL_SYNONYMS)

def is_likely_topic(text: str) -> bool:
    """ì£¼ì œ ìŠ¬ë¡¯ì— ë“¤ì–´ê°ˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ì§€ íŒë‹¨"""
    lower_text = text.lower().strip()
    return any(entry in lower_text for entry in JUJAE_SYNONYMS)

def is_valid_slot_answer(text: str) -> bool:
    """ì‚¬ìš©ì ì…ë ¥ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    text = text.strip()
    if len(text) < 3:
        return False
    lower = text.lower()
    invalid_keywords = ["ì—†", "ëª¨ë¥´", "ëª¨ë¦„", "ëª°ë¼", "ê¸€ì„", "ë¬´", "ì˜ ëª°ë¼", "ê¸°ì–µ ì•ˆ", "ìƒê° ì•ˆ"]
    return not any(kw in lower for kw in invalid_keywords)

def normalize_period(text: str) -> str:
    """ê¸°ê°„ ì…ë ¥ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
    if "ê°œì›”" in text or "ë‹¬" in text:
        number = ''.join(filter(str.isdigit, text))
        return f"{number}ê°œì›”"
    elif "ì£¼" in text:
        number = ''.join(filter(str.isdigit, text))
        return f"{number}ì£¼"
    return text.strip()

def normalize_budget(text: str) -> str:
    """ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¸ˆì•¡ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ì •ê·œí™”"""
    # ê¸ˆì•¡ ë‹¨ìœ„ê°€ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ
    if not any(unit in text for unit in ["ì›", "ë§Œì›", "ì²œì›", "ì–µ", "ì¡°"]):
        return ""
    
    # ë‹¨ìœ„ë³„ ìŠ¹ìˆ˜ ì •ì˜
    multipliers = {
        "ì¡°": 1000000000000,
        "ì–µ": 100000000,
        "ë§Œì›": 10000,
        "ì²œì›": 1000,
        "ì›": 1
    }
    
    text = text.replace(",", "")
    
    # ìˆ«ìì™€ ë‹¨ìœ„ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” íŒ¨í„´ ë§¤ì¹­
    for unit, multiplier in multipliers.items():
        if unit in text:
            match = re.search(r"(\d+)\s*" + unit, text)
            if match:
                amount = int(match.group(1)) * multiplier
                return f"{amount:,}ì›"
    
    # ë‹¨ìˆœ ìˆ«ì ì¶”ì¶œ (ë‹¨ìœ„ê°€ 'ì›'ì¸ ê²½ìš°)
    if "ì›" in text:
        match = re.search(r"(\d+)", text)
        if match:
            amount = int(match.group(1))
            return f"{amount:,}ì›"
            
    return ""

def is_valid_period(text: str) -> bool:
    """ê¸°ê°„ ì…ë ¥ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ì •ê·œí™”ë¥¼ ì‹œë„í•©ë‹ˆë‹¤."""
    text = text.strip()
    if not is_valid_slot_answer(text):  # ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬
        return False
    
    # ì •ê·œí™” ì‹œë„
    normalized = normalize_period(text)
    return any(unit in normalized for unit in ["ê°œì›”", "ì£¼"])

def infer_primary_category(topic: str, output: str) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤."""
    output = output.lower()
    topic = topic.lower()
    
    # ì›¹ í”Œë«í¼ ê´€ë ¨ í‚¤ì›Œë“œ
    if any(kw in output for kw in ["ì•±", "ì›¹", "ì‚¬ì´íŠ¸", "í”Œë«í¼", "ê´€ë¦¬ì", "ui", "í˜ì´ì§€"]):
        return "ì›¹_í”Œë«í¼"
    
    # AI ì±—ë´‡ ê´€ë ¨ í‚¤ì›Œë“œ
    elif any(kw in output for kw in ["ì±—ë´‡", "ai", "ëŒ€í™”", "ì§ˆì˜ì‘ë‹µ"]) or \
         any(kw in topic for kw in ["ëŒ€í™”", "ìƒë‹´", "ì‘ë‹µ", "ì§ˆë¬¸"]):
        return "AI_ì±—ë´‡"
    
    # ë°ì´í„°/ì‹œê°í™” ê´€ë ¨ í‚¤ì›Œë“œ
    elif any(kw in output for kw in ["ëŒ€ì‹œë³´ë“œ", "ì‹œê°í™”", "ë¶„ì„", "ë¦¬í¬íŠ¸"]) or \
         any(kw in topic for kw in ["ë°ì´í„°", "ë¶„ì„", "í†µê³„", "í˜„í™©"]):
        return "ì‹œê°í™”_ëŒ€ì‹œë³´ë“œ"
    
    # ê¸°ë³¸ê°’ì€ ì›¹ í”Œë«í¼
    return "ì›¹_í”Œë«í¼"

def infer_all_categories(topic: str, output: str) -> List[str]:
    """ì—¬ëŸ¬ ì‚°ì¶œë¬¼ì— ê¸°ë°˜í•˜ì—¬ ì í•©í•œ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¶”ë¡ """
    topic = topic.lower()
    output = output.lower()
    categories = set()

    # ì›¹/ì•± ê´€ë ¨
    if any(kw in output for kw in ["ì•±", "ì›¹", "ì‚¬ì´íŠ¸", "í”Œë«í¼"]):
        categories.add("ì›¹_í”Œë«í¼")

    # ì±—ë´‡ ê´€ë ¨
    if any(kw in output for kw in ["ì±—ë´‡", "ëŒ€í™”", "AI"]):
        categories.add("AI_ì±—ë´‡")

    # ì‹œê°í™”/ë°ì´í„° ë¶„ì„
    if any(kw in output for kw in ["ë¶„ì„", "ëŒ€ì‹œë³´ë“œ", "ë¦¬í¬íŠ¸"]):
        categories.add("ì‹œê°í™”_ëŒ€ì‹œë³´ë“œ")

    # ì´ë¯¸ì§€ íˆ´ (í–¥í›„ í•„ìš”ì‹œ SERVICE_CATEGORIESì— ì •ì˜ í•„ìš”)
    if any(kw in output for kw in ["ë””ìì¸", "ì´ë¯¸ì§€", "í”„ë¡œê·¸ë¨"]):
        categories.add("ë””ì§€í„¸_ì´ë¯¸ì§€_íˆ´")

    # SNS ë§ˆì¼€íŒ… ìš´ì˜ (í–¥í›„ í•„ìš”ì‹œ SERVICE_CATEGORIESì— ì •ì˜ í•„ìš”)
    if any(kw in output for kw in ["í‹±í†¡", "ìœ íŠœë¸Œ", "í˜ì´ìŠ¤ë¶", "ì¸ìŠ¤íƒ€"]):
        categories.add("SNS_ìš´ì˜")

    # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì¹´í…Œê³ ë¦¬ ë³´ì¥
    if not categories:
        categories.add("ì›¹_í”Œë«í¼")  # ê¸°ë³¸ê°’

    return list(categories)

def build_prompt_multicategory(user_input: str, service_categories: dict, categories: List[str], expected_budget: str = "", topic: str = "", period: str = "") -> str:
    # êµ¬ì¡°í™”ëœ ì…ë ¥ ì •ë³´ í‘œì‹œ
    prompt = "ğŸ§¾ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì •ë³´:\n"
    prompt += f"- ì£¼ì œ: {topic}\n"
    prompt += f"- ì‚°ì¶œë¬¼: {user_input}\n"
    prompt += f"- ê¸°ê°„: {period}\n"
    prompt += f"- ì˜ˆìƒ ì˜ˆì‚°: {expected_budget}\n\n"
    
    prompt += f"ğŸ’¡ ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì£¼ìš” ì„œë¹„ìŠ¤ ë²”ì£¼ëŠ” `{', '.join(categories)}`ì…ë‹ˆë‹¤.\n\n"
    
    prompt += "ğŸ§¾ ê° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ ë¹ ì§ì—†ì´ ê²¬ì ì„ ì œì‹œí•´ ì£¼ì„¸ìš”. ì¼ë¶€ í•­ëª© ëˆ„ë½ ì—†ì´ ì „ì²´ ë²”ìœ„ë¥¼ ê³ ë ¤í•´ ì£¼ì„¸ìš”.\n"
    prompt += "âš ï¸ ê° ì¹´í…Œê³ ë¦¬ëŠ” ë…ë¦½ëœ í”„ë¡œì íŠ¸ ë‹¨ìœ„ë¡œ ë³´ê³ , ê°œë³„ ê²¬ì ì„ ì œì‹œí•´ ì£¼ì„¸ìš”.\n\n"
    prompt += "ìš°ë¦¬ íšŒì‚¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n"

    for category in categories:
        if category not in service_categories:
            continue
        prompt += f"\nğŸ“‚ {category.replace('_', ' ')}\n"
        for step, content in service_categories[category].items():
            if isinstance(content, dict) and "features" in content:
                cost = content.get("cost", 0)
                features = " / ".join(content["features"])
                prompt += f"  - {step.replace('_', ' ')}: {features} (ë¹„ìš©: {cost:,}ì›)\n"
            elif isinstance(content, dict):
                for substep, subcontent in content.items():
                    if "features" in subcontent:
                        cost = subcontent.get("cost", 0)
                        features = " / ".join(subcontent["features"])
                        prompt += f"  - {step.replace('_', ' ')} > {substep}: {features} (ë¹„ìš©: {cost:,}ì›)\n"

    prompt += "\në‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”:\n\n"
    
    # ì˜ˆì‹œ í˜•ì‹ ì¶”ê°€
    prompt += """ğŸ“‚ [ì¹´í…Œê³ ë¦¬ëª…]
- í•„ìš”í•œ ë‹¨ê³„: [ê¸ˆì•¡]ì›
- ì˜ˆìƒ ê¸°ê°„: [ê¸°ê°„]

ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ê° ì¹´í…Œê³ ë¦¬ë³„ ê²¬ì ì„ ì œì‹œí•œ í›„,

ğŸ’° ì´ í•©ê³„: [ì „ì²´ ê¸ˆì•¡]ì›
"""

    return prompt

def call_gpt_full_estimate(user_input: str, topic: str, output: str, expected_budget: str, period: str) -> str:
    """ì „ì²´ ê²¬ì ë§Œ ìš”ì²­ (ğŸ”„ ì¶•ì†Œ ì œì•ˆ ì œì™¸)"""
    prompt = build_prompt_multicategory(
        user_input, SERVICE_CATEGORIES,
        infer_all_categories(topic, output),
        expected_budget, topic, period
    )
    # í”„ë¡¬í”„íŠ¸ì—ì„œ ì¶•ì†Œ ì œì•ˆ ì•ˆë‚´ ì‚­ì œ
    prompt = re.sub(r"\n*ë§Œì•½ ì´ í•©ê³„.*?ì¶•ì†Œì•ˆë„ í•¨ê»˜ ì œì‹œí•´ ì£¼ì„¸ìš”\.", "", prompt, flags=re.DOTALL)

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ IT ê²¬ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                  {"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=1200
    )
    return response.choices[0].message.content

def call_gpt_shrunk_only(full_prompt: str, user_budget: str = "") -> str:
    """ì¶•ì†Œ ì œì•ˆë§Œ GPTì— ìš”ì²­ (ì‚¬ìš©ì ì˜ˆì‚°ì´ ë„ˆë¬´ ë‚®ì„ ê²½ìš°, ìµœì†Œ êµ¬ì„± ê²¬ì  ì œì•ˆ)"""
    prompt = ""

    # ì˜ˆì‚° íŒŒì‹± (ìˆ«ìë§Œ ì¶”ì¶œ)
    min_reasonable_budget = 300_000  # ìµœì†Œ ìˆ˜ìš© ê°€ëŠ¥í•œ ê²¬ì 
    user_budget_value = 0
    match = re.search(r"([\d,]+)", user_budget.replace(",", ""))
    if match:
        user_budget_value = int(match.group(1))

    # ì˜ˆì‚°ì´ ë„ˆë¬´ ë‚®ì€ ê²½ìš° GPT ì•ˆë‚´ ì¶”ê°€
    if user_budget_value < min_reasonable_budget:
        prompt += f"â— ì‚¬ìš©ìì˜ ì…ë ¥ ì˜ˆì‚°ì´ {user_budget}ìœ¼ë¡œ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. í˜„ì‹¤ì ìœ¼ë¡œ ê°€ëŠ¥í•œ ìµœì†Œí•œì˜ êµ¬ì„± ê²¬ì ì„ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.\n"
        prompt += "ì˜ˆì‚°ì´ ë¶€ì¡±í•œ ìƒí™©ì—ì„œë„ í•„ìˆ˜ì ì¸ ê¸°ëŠ¥ë§Œìœ¼ë¡œ êµ¬ì„±í•´ ì£¼ì‹œê³ , ê·¸ì— ë§ëŠ” ì ì ˆí•œ ë¹„ìš©ì„ ì œì‹œí•´ ì£¼ì„¸ìš”.\n\n"
    else:
        prompt += f"â—ï¸ì˜ˆì‚°ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”: ìµœëŒ€ {user_budget} ì´í•˜ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"

    prompt += "ğŸ›  ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì„œë¹„ìŠ¤ ë²”ìœ„ì…ë‹ˆë‹¤. ìµœì†Œ ê¸°ëŠ¥ ì¤‘ì‹¬ì˜ 'ğŸ”„ ì¶•ì†Œ ì œì•ˆ'ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
    prompt += full_prompt
    prompt += "\n\nğŸ”„ ì¶•ì†Œ ì œì•ˆ:\n[ì¹´í…Œê³ ë¦¬ë³„ ì¶•ì†Œ ê²¬ì  í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.]"

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{
            "role": "system", 
            "content": "ë‹¹ì‹ ì€ IT ê²¬ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì˜ˆì‚°ì´ ë„ˆë¬´ ë‚®ì„ ê²½ìš°, í˜„ì‹¤ì ìœ¼ë¡œ ê°€ëŠ¥í•œ ìµœì†Œ êµ¬ì„±ì„ ì œì•ˆí•˜ê³ , ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° ì˜ˆì‚° ì´í•˜ë¡œ ê²¬ì ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
        }, {
            "role": "user", 
            "content": prompt
        }],
        temperature=0.7,
        max_tokens=800
    )
    return response.choices[0].message.content.strip()

# process_gpt í•¨ìˆ˜ ìˆ˜ì •
async def process_gpt(user_id: str, user_input: str, topic: str = "", output: str = "", expected_budget: str = "", period: str = ""):
    USER_INPUTS[user_id] = user_input
    GPT_RESPONSES[user_id] = "â³ ìš”ì²­ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
    
    # ì „ì²´ ê²¬ì ë§Œ ë¨¼ì € ìƒì„±
    full_response = call_gpt_full_estimate(user_input, topic, output, expected_budget, period)
    GPT_RESPONSES[user_id] = full_response

@app.post("/kakao/webhook")
async def kakao_webhook(request: Request, background_tasks: BackgroundTasks):
    """ì¹´ì¹´ì˜¤í†¡ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸"""
    # ë³€ìˆ˜ ì´ˆê¸°í™”
    user_id = ""
    utterance = ""
    params = {}
    detail_params = {}

    try:
        body = await request.json()
        user_id = body.get("userRequest", {}).get("user", {}).get("id", str(uuid.uuid4()))
        utterance = body.get("userRequest", {}).get("utterance", "")
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ìƒì„¸ íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        params = body.get("action", {}).get("params", {})
        detail_params = body.get("action", {}).get("detailParams", {})
        
        # ê²¬ì  ê²°ê³¼ í™•ì¸ ìš”ì²­ ì²˜ë¦¬
        if utterance.startswith("ê²¬ì  ê²°ê³¼ í™•ì¸:"):
            result_user_id = utterance.split("ê²¬ì  ê²°ê³¼ í™•ì¸:")[-1].strip()
            return await get_result(result_user_id)
            
        # ì¶•ì†Œ ê²¬ì  í™•ì¸ ìš”ì²­ ì²˜ë¦¬
        if utterance.startswith("ì¶•ì†Œ ê²¬ì  í™•ì¸:"):
            shrunk_user_id = utterance.split("ì¶•ì†Œ ê²¬ì  í™•ì¸:")[-1].strip()
            return await get_shrunk_result(shrunk_user_id)

        # ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜ ì‹œ ìƒíƒœ ì´ˆê¸°í™”
        if utterance == "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜":
            USER_SLOT_STATE.pop(user_id, None)
            USER_INPUTS.pop(user_id, None)
            GPT_RESPONSES.pop(user_id, None)
        
        # ìŠ¬ë¡¯ í•„ë§ ì¤‘ì¸ì§€ ì—¬ë¶€ í™•ì¸
        in_slot_filling = user_id in USER_SLOT_STATE and any(
            USER_SLOT_STATE[user_id].get(slot, "") == "" for slot in ["ì£¼ì œ", "ì‚°ì¶œë¬¼", "ê¸°ê°„", "ì˜ˆìƒ_ê²¬ì "]
        )
        
        # ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ â†’ ìŠ¬ë¡¯ í•„ë§ ì¤‘ì´ë©´ ê²€ì‚¬ ê±´ë„ˆëœ€
        if not in_slot_filling and not any(keyword in utterance for keyword in ["í¬íŠ¸í´ë¦¬ì˜¤", "ê°€ê²©", "ê²¬ì ", "ë¹„ìš©", "í”„ë¡œì íŠ¸", "ê°œë°œ", "ì œì‘"]):
            return JSONResponse(content={
                "version": "2.0",
                "template": {
                    "outputs": [{
                        "simpleText": {
                            "text": "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸ê³¼ ê²¬ì  ìƒë‹´ë§Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ğŸ˜…\n\në‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë¬¸ì˜í•´ì£¼ì„¸ìš”:\n- í”„ë¡œì íŠ¸ ê²¬ì  ë¬¸ì˜\n- í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸\n- ê°œë°œ ë¹„ìš© ìƒë‹´"
                        }
                    }],
                    "quickReplies": [{
                        "messageText": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜",
                        "action": "message",
                        "label": "ê²¬ì  ë¬¸ì˜í•˜ê¸°"
                    }]
                }
            })
    
        # ê¸°ì¡´ ìƒíƒœ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if user_id not in USER_SLOT_STATE:
            USER_SLOT_STATE[user_id] = {"ì£¼ì œ": "", "ì‚°ì¶œë¬¼": "", "ê¸°ê°„": "", "ì˜ˆìƒ_ê²¬ì ": "", "retry_count": 0}
            
        user_state = USER_SLOT_STATE[user_id]
        
        # í† í°í™” ë° ì „ì²˜ë¦¬
        tokens = utterance.replace(",", " ").replace("ì„", "").replace("ë¥¼", "").split()
        tokens = [t.strip().lower() for t in tokens]
        
        # ì£¼ì œê°€ ë¹„ì–´ ìˆìœ¼ë©´ í† í°ì—ì„œ ë§¤ì¹­ ì‹œë„
        if user_state["ì£¼ì œ"] == "":
            for token in tokens:
                if is_likely_topic(token):
                    user_state["ì£¼ì œ"] = token
                    break
            if user_state["ì£¼ì œ"] == "":
                topic_match = match_similar_slot_lightweight(utterance, "ì£¼ì œ")
                if topic_match:
                    user_state["ì£¼ì œ"] = topic_match
                else:
                    return JSONResponse(content={
                        "version": "2.0",
                        "template": {
                            "outputs": [{
                                "simpleText": {
                                    "text": "ğŸ“ í”„ë¡œì íŠ¸ ì£¼ì œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”! (ì˜ˆ: ì‡¼í•‘ëª°, êµìœ¡ í”Œë«í¼ ë“±)"
                                }
                            }]
                        }
                    })
        
        # ì‚°ì¶œë¬¼ì´ ë¹„ì–´ ìˆìœ¼ë©´ ì—¬ëŸ¬ í† í°ì—ì„œ ì¶”ì¶œ
        if user_state["ì‚°ì¶œë¬¼"] == "":
            matched_outputs = [entry for entry in SANCHUL_SYNONYMS if entry in utterance.lower()]
            if matched_outputs:
                user_state["ì‚°ì¶œë¬¼"] = ", ".join(sorted(set(matched_outputs)))
            else:
                output_match = match_similar_slot_lightweight(utterance, "ì‚°ì¶œë¬¼")
                if output_match:
                    user_state["ì‚°ì¶œë¬¼"] = output_match
                else:
                    return JSONResponse(content={
                        "version": "2.0",
                        "template": {
                            "outputs": [{
                                "simpleText": {
                                    "text": "ğŸ“¦ ì–´ë–¤ ì‚°ì¶œë¬¼ì„ ì›í•˜ì‹œë‚˜ìš”? (ì˜ˆ: ì›¹ì‚¬ì´íŠ¸, ì•±, ê´€ë¦¬ì í˜ì´ì§€ ë“±)"
                                }
                            }]
                        }
                    })
        
        # ê¸°ê°„ ì…ë ¥ì´ ì—†ìœ¼ë©´ ìš”ì²­
        if user_state["ê¸°ê°„"] == "":
            if is_valid_period(utterance):
                user_state["ê¸°ê°„"] = normalize_period(utterance)
            else:
                return JSONResponse(content={
                    "version": "2.0",
                    "template": {
                        "outputs": [{
                            "simpleText": {
                                "text": "âŒ› ì˜ˆìƒ ê°œë°œ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì„¸ìš”! (ì˜ˆ: 2ê°œì›”, 3ì£¼ ë“±)"
                            }
                        }]
                    }
                })

        # ì˜ˆìƒ ê²¬ì  ìŠ¬ë¡¯ ì¶”ê°€
        if "ì˜ˆìƒ_ê²¬ì " not in user_state:
            user_state["ì˜ˆìƒ_ê²¬ì "] = ""

        # ê²¬ì  ê²°ê³¼ ì‘ë‹µì— í¬í•¨ë˜ì—ˆì„ ê²½ìš° ì¶”ì¶œí•´ì„œ ì €ì¥
        if user_state["ì˜ˆìƒ_ê²¬ì "] == "" and utterance.startswith("ê²¬ì  ê²°ê³¼ í™•ì¸:"):
            gpt_result = GPT_RESPONSES.get(user_id, "")
            if "ì´ ê²¬ì " in gpt_result:
                lines = gpt_result.splitlines()
                for line in lines:
                    if "ì´ ê²¬ì " in line:
                        user_state["ì˜ˆìƒ_ê²¬ì "] = line.strip()
                        break

        # ê²¬ì ì´ ë¹„ì–´ ìˆìœ¼ë©´ ë‹¤ì‹œ ë¬¼ì–´ë³´ê¸°
        if user_state["ì˜ˆìƒ_ê²¬ì "] == "":
            normalized = normalize_budget(utterance)
            if normalized:
                user_state["ì˜ˆìƒ_ê²¬ì "] = normalized
            else:
                return JSONResponse(content={
                    "version": "2.0",
                    "template": {
                        "outputs": [{
                            "simpleText": {
                                "text": "ğŸ’° ëŒ€ëµ ì–´ëŠ ì •ë„ì˜ ì˜ˆì‚°ì„ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”? (ì˜ˆ: 100ë§Œì›, 2000ë§Œì› ë“±)"
                            }
                        }]
                    }
                })
        
        # ìƒì„¸ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ê²½ìš° ìš°ì„  ì ìš©
        for slot in ["ì£¼ì œ", "ì‚°ì¶œë¬¼", "ê¸°ê°„", "ì˜ˆìƒ_ê²¬ì "]:
            if slot in detail_params and detail_params[slot].get("origin"):
                user_state[slot] = detail_params[slot]["origin"]
            elif slot in params:
                user_state[slot] = params.get(slot) or params.get(f"${slot}", "")
        
        # ëª¨ë“  ìŠ¬ë¡¯ì´ ì±„ì›Œì§„ ê²½ìš°ì—ë§Œ GPT ìš”ì²­ ì²˜ë¦¬
        if user_state["ì£¼ì œ"] != "" and user_state["ì‚°ì¶œë¬¼"] != "" and user_state["ê¸°ê°„"] != "" and user_state["ì˜ˆìƒ_ê²¬ì "] != "":
            user_input_parts = [
                f"ğŸ–‹ ì£¼ì œ: {user_state['ì£¼ì œ']}",
                f"ğŸ§¾ ì‚°ì¶œë¬¼: {user_state['ì‚°ì¶œë¬¼']}",
                f"ğŸ•’ ê¸°ê°„: {user_state['ê¸°ê°„']}",
                f"ğŸ’° ì˜ˆì‚°: {user_state['ì˜ˆìƒ_ê²¬ì ']}"
            ]
            user_input = "\n".join(user_input_parts)
            
            USER_INPUTS[user_id] = user_input
            background_tasks.add_task(
                process_gpt,
                user_id,
                user_input,
                user_state["ì£¼ì œ"],
                user_state["ì‚°ì¶œë¬¼"],
                user_state["ì˜ˆìƒ_ê²¬ì "],
                user_state["ê¸°ê°„"]
            )
            
            return JSONResponse(content={
                "version": "2.0",
                "template": {
                    "outputs": [{
                        "simpleText": {
                            "text": f"ğŸ“ ëª¨ë“  ì •ë³´ë¥¼ ë°›ì•˜ì–´ìš”! ëª‡ ì´ˆ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n\nğŸ‘‰ í™•ì¸: /result/{user_id}"
                        }
                    }],
                    "quickReplies": [{
                        "messageText": f"ê²¬ì  ê²°ê³¼ í™•ì¸:{user_id}",
                        "action": "message",
                        "label": "ê²¬ì  ê²°ê³¼ í™•ì¸"
                    }]
                }
            })
            
    except Exception as e:
        return JSONResponse(content={
            "version": "2.0",
            "template": {
                "outputs": [{
                    "simpleText": {
                        "text": f"âš ï¸ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\nì˜¤ë¥˜ ë‚´ìš©: {str(e)}"
                    }
                }]
            }
        })

@app.get("/result/{user_id}")
async def get_result(user_id: str):
    """ê²°ê³¼ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    response_text = GPT_RESPONSES.get(user_id, "âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìš”ì²­ IDì´ê±°ë‚˜ ì•„ì§ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.")
    user_input = USER_INPUTS.get(user_id, "ì…ë ¥ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # quick_replies ì´ˆê¸°í™”ë¥¼ ë¨¼ì € ìˆ˜í–‰
    quick_replies = [{
        "messageText": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜",
        "action": "message",
        "label": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜"
    }]

    # ì…ë ¥ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶•ì†Œ ê²¬ì  ë²„íŠ¼ ì¶”ê°€
    if user_id in USER_INPUTS:
        quick_replies.append({
            "messageText": f"ì¶•ì†Œ ê²¬ì  í™•ì¸:{user_id}",
            "action": "message",
            "label": "ì¶•ì†Œ ê²¬ì ë§Œ ë³´ê¸°"
        })
    
    return {
        "version": "2.0",
        "template": {
            "outputs": [{
                "simpleText": {
                    "text": f"{response_text}\n\nğŸ—‚ï¸ ì…ë ¥ ì •ë³´:\n{user_input}"
                }
            }],
            "quickReplies": quick_replies
        }
    }

@app.get("/shrunk_result/{user_id}")
async def get_shrunk_result(user_id: str):
    """ì¶•ì†Œ ê²¬ì ì€ ë²„íŠ¼ ëˆŒë €ì„ ë•Œ GPT ë‹¤ì‹œ í˜¸ì¶œ"""
    if user_id not in USER_INPUTS:
        return {"version": "2.0", "template": {"outputs": [{"simpleText": {"text": "âŒ ì…ë ¥ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}}]}}

    user_input = USER_INPUTS[user_id]
    # ê¸°ì¡´ full prompt ì¬í™œìš©
    topic = USER_SLOT_STATE.get(user_id, {}).get("ì£¼ì œ", "")
    output = USER_SLOT_STATE.get(user_id, {}).get("ì‚°ì¶œë¬¼", "")
    budget = USER_SLOT_STATE.get(user_id, {}).get("ì˜ˆìƒ_ê²¬ì ", "")
    period = USER_SLOT_STATE.get(user_id, {}).get("ê¸°ê°„", "")

    # ìºì‹œëœ ì¶•ì†Œ ê²¬ì ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
    if user_id in SHRUNK_RESPONSES and SHRUNK_RESPONSES[user_id]:
        shrunk_only_text = SHRUNK_RESPONSES[user_id]
    else:
        full_prompt = build_prompt_multicategory(user_input, SERVICE_CATEGORIES, infer_all_categories(topic, output), budget, topic, period)
        shrunk_only_text = call_gpt_shrunk_only(full_prompt, user_budget=budget)
        SHRUNK_RESPONSES[user_id] = shrunk_only_text  # ìºì‹±

    return {
        "version": "2.0",
        "template": {
            "outputs": [{"simpleText": {"text": shrunk_only_text}}],
            "quickReplies": [{
                "messageText": f"ê²¬ì  ê²°ê³¼ í™•ì¸:{user_id}",
                "action": "message",
                "label": "ì „ì²´ ê²¬ì  ë³´ê¸°"
            }]
        }
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy"}

# ì§ì ‘ ì‹¤í–‰ ì‹œ ì„œë²„ êµ¬ë™
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))  # Railwayë‚˜ Fly.io í™˜ê²½ë³€ìˆ˜ ëŒ€ì‘
    uvicorn.run(app, host="0.0.0.0", port=port)
