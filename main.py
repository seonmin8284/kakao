from fastapi import FastAPI, BackgroundTasks, Request
from pydantic import BaseModel
from fastapi.responses import JSONResponse
from typing import Optional, Dict, Any
from sentence_transformers import SentenceTransformer, util
import os
from tasks import process_utterance_async, set_project_data, ANALYSIS_RESULTS
import openai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")


# ëª¨ë¸ ë¡œë”©
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# ì„œë¹„ìŠ¤ ë° í”„ë¡œì íŠ¸ ë°ì´í„° (ì¹´í…Œê³ ë¦¬ ê¸°ì¤€ ê²¬ì  ì‚°ì •)
SERVICE_CATEGORIES = {
    "ì‹œê°í™”_ëŒ€ì‹œë³´ë“œ": {
        "ê¸°íš_ìš”êµ¬ì‚¬í•­_ì •ì˜": {
            "features": ["ë¶„ì„ ëª©ì  ë° ì£¼ìš” KPI ì •ì˜", "ì‚¬ìš©ì ìš”êµ¬ ì •ë¦¬", "ë°ì´í„° ì‹œê°í™” ë°©í–¥ ìˆ˜ë¦½"],
            "outputs": ["ëŒ€ì‹œë³´ë“œ ê¸°íšì„œ", "KPI ì •ì˜ì„œ", "ì™€ì´ì–´í”„ë ˆì„"],
            "cost": 400000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ì „ì²˜ë¦¬": {
            "features": ["ë‚´ë¶€/ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘", "ë°ì´í„° ì •ì œ ë° ê°€ê³µ", "Power BI/Tableau ì ì¬"],
            "outputs": ["ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹", "í…Œì´ë¸” êµ¬ì¡° ì„¤ê³„"],
            "cost": 800000
        },
        "ëŒ€ì‹œë³´ë“œ_í”„ë¡œí† íƒ€ì…_ì œì‘": {
            "features": ["í•µì‹¬ KPI ìœ„ì£¼ì˜ ì‹œê°í™” ëª¨ë“ˆ ê°œë°œ", "í”¼ë“œë°± ë°˜ì˜ êµ¬ì¡° êµ¬ì„±"],
            "outputs": ["ì´ˆê¸° ëŒ€ì‹œë³´ë“œ MVP", "í˜ì´ì§€ë³„ ê¸°ëŠ¥ ì„¤ëª…ì„œ"],
            "cost": 1000000
        },
        "ì‚¬ìš©ì_ë§ì¶¤í˜•_ê¸°ëŠ¥_ì¶”ê°€": {
            "features": ["í•„í„°", "Drill-Down", "ê¶Œí•œë³„ ë·°", "ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ ìë™í™”"],
            "outputs": ["ì‚¬ìš©ì ì¸í„°ë™ì…˜ ê¸°ëŠ¥ ì ìš©ëœ ì™„ì„±í˜• ëŒ€ì‹œë³´ë“œ"],
            "cost": 1000000
        },
        "ìë™í™”_ìš´ì˜_ì—°ë™": {
            "features": ["ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸", "ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§(Airflow)", "ì•Œë¦¼/ë¦¬í¬íŠ¸ ìë™í™”"],
            "outputs": ["ìë™ ë¦¬í¬íŠ¸ PDF", "Airflow DAG", "ë©”ì¼ ë°œì†¡ ì—°ë™"],
            "cost": 1000000
        },
        "ê´€ë¦¬ì_êµìœ¡_ì „ë‹¬": {
            "features": ["ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±", "ê´€ë¦¬ì êµìœ¡ ì„¸ì…˜", "ìœ ì§€ë³´ìˆ˜ ë¬¸ì„œ ì „ë‹¬"],
            "outputs": ["ìš´ì˜ ë§¤ë‰´ì–¼", "ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²• PDF"],
            "cost": 0
        }
    },
    "AI_ì±—ë´‡": {
        "ê¸°íš_ì¡°ì‚¬": {
            "features": ["ìš”êµ¬ì‚¬í•­ ë¶„ì„", "ìœ ì¦ˆì¼€ì´ìŠ¤ ì •ì˜", "ê²½ìŸ ë¶„ì„", "AI í™œìš©ë°©ì•ˆ ì„¤ê³„"],
            "cost": 500000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ì „ì²˜ë¦¬": {
            "features": ["í¬ë¡¤ë§", "ì •ì œ", "ë ˆì´ë¸”ë§", "í† í¬ë‚˜ì´ì§•", "ì´ë¯¸ì§€/ìŒì„±/í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì„±"],
            "cost": 500000
        },
        "AI_ëª¨ë¸_ê°œë°œ": {
            "APIê³ ë„í™”": {
                "features": ["ìŒì„±/ì´ë¯¸ì§€/ì–¸ì–´ ìƒì„± ë˜ëŠ” ì¸ì‹ ëª¨ë¸ ê°œë°œ", "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§"],
                "cost": 2000000
            },
            "íŒŒì¸íŠœë‹": {
                "features": ["ì˜¤í”ˆì†ŒìŠ¤ LLM (LLaMA, Mistral ë“±) Fine-tuning", "ë°ì´í„° ê¸°ë°˜ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì„±"],
                "cost": 3000000
            }
        },
        "ëª¨ë¸_í‰ê°€_ê°œì„ ": {
            "features": ["ì •í™•ë„/ì •ë°€ë„/F1 Score", "ì‹¤ì œ QA ì‹œë‚˜ë¦¬ì˜¤ ì„±ëŠ¥ í‰ê°€", "ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„"],
            "cost": 1500000
        },
        "í”Œë«í¼_MVP_êµ¬í˜„": {
            "features": ["ë°±ì—”ë“œ API", "ì±—ë´‡ UI(ì›¹/ì•±)", "ì¸ì¦/ê¶Œí•œ ì‹œìŠ¤í…œ", "ëŒ€í™” íë¦„ êµ¬í˜„"],
            "cost": 3000000
        },
        "ìš´ì˜_ìë™í™”_ëª¨ë‹ˆí„°ë§": {
            "features": ["ëª¨ë¸ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸", "ë¡œê·¸ ìˆ˜ì§‘", "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"],
            "cost": 1000000
        },
        "êµìœ¡_ì „ë‹¬": {
            "features": ["ê´€ë¦¬ì ë° ì‚¬ìš©ì ë§¤ë‰´ì–¼ ì œê³µ", "ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ", "ê¸°ìˆ  ì´ì „"],
            "cost": 0
        }
    },
    "ë°ì´í„°_ì—”ì§€ë‹ˆì–´ë§": {
        "ìš”êµ¬ì‚¬í•­_ì •ì˜_ì„¤ê³„": {
            "features": ["ìˆ˜ì§‘ ëŒ€ìƒ ì •ì˜", "ìŠ¤í‚¤ë§ˆ ì„¤ê³„", "íŒŒì´í”„ë¼ì¸ êµ¬ì¡° ì„¤ê³„"],
            "cost": 500000
        },
        "ë°ì´í„°_ìˆ˜ì§‘_ëª¨ë“ˆ_ê°œë°œ": {
            "features": ["Public API", "ì›¹ í¬ë¡¤ë§", "DB ì¶”ì¶œ ë“± ë°ì´í„° ìˆ˜ì§‘ ìë™í™” êµ¬í˜„"],
            "cost": 500000
        },
        "ë°ì´í„°_ì²˜ë¦¬_ì •ì œ": {
            "features": ["ê²°ì¸¡ì¹˜ ì²˜ë¦¬", "ì¤‘ë³µ ì œê±°", "í¬ë§· ë³€í™˜", "ì»¬ëŸ¼ ì •ë¦¬ ë“± ì „ì²˜ë¦¬ ë¡œì§ ê°œë°œ"],
            "cost": 500000
        },
        "ì €ì¥_ì ì¬_ìë™í™”": {
            "features": ["ì •ì œ ë°ì´í„°ì˜ ì €ì¥ (SQL, Data Lake, Warehouse ë“±) ë° ë²„ì „ ê´€ë¦¬"],
            "cost": 500000
        },
        "íŒŒì´í”„ë¼ì¸_ìë™í™”": {
            "features": ["Apache Airflow", "Python ìŠ¤ì¼€ì¤„ëŸ¬", "CI/CD ë“± í™œìš©í•œ ìë™í™” êµ¬ì„±"],
            "cost": 700000
        },
        "ëª¨ë‹ˆí„°ë§_ì˜¤ë¥˜_ì•Œë¦¼": {
            "features": ["ì‹¤íŒ¨ ë¡œê·¸ ìˆ˜ì§‘", "ì‘ì—… ì„±ê³µ ì—¬ë¶€ ì‹œê°í™”", "ìŠ¬ë™/ë©”ì¼ ì•Œë¦¼ ì—°ë™"],
            "cost": 500000
        },
        "ë¬¸ì„œí™”_ì „ë‹¬": {
            "features": ["ì „ì²´ ë°ì´í„° íë¦„ë„", "ìš´ì˜ ê°€ì´ë“œ", "ìœ ì§€ë³´ìˆ˜ ë¬¸ì„œ ì œê³µ"],
            "cost": 0
        }
    },
    "í”Œë«í¼": {
        "ê¸°íš_ìš”êµ¬ì‚¬í•­_ì •ì˜": {
            "features": ["ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„", "í•µì‹¬ ê¸°ëŠ¥ ë„ì¶œ", "ê²½ìŸ ë²¤ì¹˜ë§ˆí‚¹", "í”Œë«í¼ êµ¬ì¡° ì„¤ê³„", "ê¸°ìˆ  ìŠ¤íƒ ì„ ì •", "í´ë¼ìš°ë“œ ì¸í”„ë¼ ì´ˆì•ˆ ìˆ˜ë¦½"],
            "cost": 1000000
        },
        "í”Œë«í¼_í”„ë¡ íŠ¸ì—”ë“œ_ê°œë°œ": {
            "features": ["ì‚¬ìš©ì UI/UX êµ¬í˜„ (React/Vue ê¸°ë°˜)", "ë°˜ì‘í˜• ë””ìì¸ ì ìš©"],
            "cost": 2000000
        },
        "í”Œë«í¼_ë°±ì—”ë“œ_ê°œë°œ": {
            "features": ["API ì„œë²„", "ì¸ì¦ ì‹œìŠ¤í…œ", "DB ì—°ë™", "ì•Œë¦¼ ì‹œìŠ¤í…œ ë“± êµ¬í˜„"],
            "cost": 3000000
        },
        "ìš´ì˜ì_ê´€ë¦¬_ì‹œìŠ¤í…œ": {
            "features": ["ê´€ë¦¬ì í˜ì´ì§€", "ê¶Œí•œ ê´€ë¦¬", "ì‚¬ìš©ì/ë°ì´í„° ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥"],
            "cost": 2000000
        },
        "ë°°í¬_í†µí•©_ìœ ì§€ë³´ìˆ˜": {
            "features": ["ë„ë©”ì¸ ì—°ë™", "ì„œë²„ ë°°í¬", "ì´ˆê¸° ì˜¤ë¥˜ ëŒ€ì‘ ë° ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ ì œê³µ"],
            "cost": 1000000
        }
    }
}

# í”„ë¡œì íŠ¸ ë°ì´í„° ì„¤ì •
PROJECT_TO_OUTPUTS = {
    "ëŒ€ì‹œë³´ë“œ ê°œë°œ": ["ë°ì´í„° ì‹œê°í™”", "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "KPI ëŒ€ì‹œë³´ë“œ"],
    "AI ì±—ë´‡ êµ¬ì¶•": ["ìì—°ì–´ ì²˜ë¦¬", "ëŒ€í™” ì‹œìŠ¤í…œ", "API ì—°ë™"],
    "ë°ì´í„° íŒŒì´í”„ë¼ì¸": ["ETL í”„ë¡œì„¸ìŠ¤", "ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤", "ìë™í™” ìŠ¤í¬ë¦½íŠ¸"],
    "ì›¹ í”Œë«í¼ ê°œë°œ": ["í”„ë¡ íŠ¸ì—”ë“œ", "ë°±ì—”ë“œ", "ë°ì´í„°ë² ì´ìŠ¤"]
}

# ì´ˆê¸° ë°ì´í„° ì„¤ì •
set_project_data(PROJECT_TO_OUTPUTS, SERVICE_CATEGORIES)

SIMILARITY_THRESHOLD = 0.75

app = FastAPI()

# Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
class UserProperties(BaseModel):
    properties: Dict[str, Any] = {}

class User(BaseModel):
    id: str
    type: str
    properties: Dict[str, Any] = {}

class BlockInfo(BaseModel):
    id: str
    name: str

class UserRequest(BaseModel):
    timezone: str
    params: Dict[str, Any]
    block: BlockInfo
    utterance: str
    lang: Optional[str]
    user: User

class BotInfo(BaseModel):
    id: str
    name: str

class ActionParams(BaseModel):
    name: str
    clientExtra: Optional[str]
    params: Dict[str, Any]
    id: str
    detailParams: Dict[str, Any]

class KakaoRequest(BaseModel):
    intent: BlockInfo
    userRequest: UserRequest
    bot: BotInfo
    action: ActionParams

# ê¸°ëŠ¥ ìœ ì‚¬ë„ ë§¤ì¹­
def find_similar_project(query: str) -> tuple[str, float]:
    query_embedding = model.encode(query)
    max_similarity = 0
    best_match = None
    for project, features in PROJECT_TO_OUTPUTS.items():
        text = f"{project} - {', '.join(features)}"
        similarity = util.pytorch_cos_sim(query_embedding, model.encode(text)).item()
        if similarity > max_similarity:
            max_similarity = similarity
            best_match = project
    return best_match, max_similarity

# ì‚°ì¶œë¬¼ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ
def extract_outputs_from_text(text: str) -> list[str]:
    matched = []
    all_outputs = set(sum(PROJECT_TO_OUTPUTS.values(), []))
    for output in all_outputs:
        if output.lower().replace("_", "") in text.lower().replace(" ", ""):
            matched.append(output)
    return matched

def build_prompt(user_input: str, service_categories: Dict[str, Any]) -> str:
    """ì‚¬ìš©ì ì…ë ¥ê³¼ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPT í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    prompt = f"ì‚¬ìš©ìì˜ ìš”ì²­:\n\"{user_input}\"\n\n"
    prompt += "ìš°ë¦¬ íšŒì‚¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n"

    for category, steps in service_categories.items():
        prompt += f"\nğŸ“‚ {category.replace('_', ' ')}\n"
        for step, content in steps.items():
            if isinstance(content, dict) and "features" in content:
                cost = content.get("cost", 0)
                features = " / ".join(content["features"])
                prompt += f"  - {step.replace('_', ' ')}: {features} (ë¹„ìš©: {cost:,}ì›)\n"
            elif isinstance(content, dict):
                for substep, subcontent in content.items():
                    if "features" in subcontent:
                        cost = subcontent.get("cost", 0)
                        features = " / ".join(subcontent["features"])
                        prompt += f"  - {step.replace('_', ' ')} > {substep}: {features} (ë¹„ìš©: {cost:,}ì›)\n"

    prompt += "\në‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”:\n"
    prompt += "1. ì¶”ì²œ ì„œë¹„ìŠ¤: ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬\n"
    prompt += "2. í•„ìš”í•œ ë‹¨ê³„: ê° ë‹¨ê³„ë³„ ì£¼ìš” ê¸°ëŠ¥ê³¼ ë¹„ìš©\n"
    prompt += "3. ì˜ˆìƒ ê¸°ê°„: ì „ì²´ í”„ë¡œì íŠ¸ ì†Œìš” ê¸°ê°„\n"
    prompt += "4. ì´ ê²¬ì : ëª¨ë“  ë‹¨ê³„ì˜ ë¹„ìš© í•©ê³„\n"
    prompt += "5. ì¶”ê°€ ê³ ë ¤ì‚¬í•­: ì„ íƒì ìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ë‚˜ ëŒ€ì•ˆ\n"
    
    return prompt

def call_gpt_for_estimate(user_input: str) -> str:
    """GPT APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê²¬ì  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        prompt = build_prompt(user_input, SERVICE_CATEGORIES)
        
        response = openai.ChatCompletion.create(
            model="gpt-4",  # ë˜ëŠ” "gpt-3.5-turbo"
            messages=[
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ê²¬ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ìƒë‹´í•´ì£¼ì„¸ìš”. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ë˜, í˜•ì‹ì€ ë°˜ë“œì‹œ ì§€ì •ëœ ëŒ€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ ì£„ì†¡í•©ë‹ˆë‹¤. ê²¬ì  ì‚°ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\nì˜¤ë¥˜ ë‚´ìš©: {str(e)}"

@app.post("/kakao/webhook")
async def kakao_webhook(request: Request):
    """ì¹´ì¹´ì˜¤í†¡ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        
        # GPT APIë¡œ ì‘ë‹µ ìƒì„±
        gpt_reply = call_gpt_for_estimate(utterance)
        
        # ì¹´ì¹´ì˜¤í†¡ ì‘ë‹µ í¬ë§·
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": gpt_reply
                        }
                    }
                ],
                "quickReplies": [
                    {
                        "messageText": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜",
                        "action": "message",
                        "label": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜"
                    }
                ]
            }
        }
        
        return JSONResponse(content=response)
        
    except Exception as e:
        error_response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": f"âš ï¸ ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\nì˜¤ë¥˜ ë‚´ìš©: {str(e)}"
                        }
                    }
                ]
            }
        }
        return JSONResponse(content=error_response)

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy"}

@app.get("/kakao/result/{user_id}")
async def get_analysis_result(user_id: str):
    """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ API"""
    result = ANALYSIS_RESULTS.get(user_id, "ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    response = {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": result
                    }
                }
            ],
            "quickReplies": [
                {
                    "messageText": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜",
                    "action": "message",
                    "label": "ìƒˆë¡œìš´ ê²¬ì  ë¬¸ì˜"
                }
            ]
        }
    }
    
    return JSONResponse(content=response)
